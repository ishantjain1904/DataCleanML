{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe16e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer,RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer,MaxAbsScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d854dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxabs_scaler(X_train,X_test):\n",
    "    rs = MaxAbsScaler()\n",
    "    X_train4 = X_train.copy()\n",
    "    X_test4  = X_test.copy()\n",
    "    \n",
    "    X_train4 = rs.fit_transform(X_train4)\n",
    "    X_test4 = rs.transform(X_test4)\n",
    "    \n",
    "    return X_train4,X_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bd83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scaler(X_train,X_test):\n",
    "    rs = RobustScaler()\n",
    "    X_train3 = X_train.copy()\n",
    "    X_test3  = X_test.copy()\n",
    "    \n",
    "    X_train3 = rs.fit_transform(X_train3)\n",
    "    X_test3 = rs.transform(X_test3)\n",
    "    \n",
    "    return X_train3,X_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5c784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_transforemer_scaler(X_train,X_test):\n",
    "    qts = QuantileTransformer()\n",
    "    X_train5 = X_train.copy()\n",
    "    X_test5  = X_test.copy()\n",
    "    \n",
    "    X_train5 = qts.fit_transform(X_train5)\n",
    "    X_test5 = qts.transform(X_test5)\n",
    "    \n",
    "    return X_train5,X_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e600c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train,X_test):\n",
    "    mn = MinMaxScaler()\n",
    "    X_train2 = X_train.copy()\n",
    "    X_test2  = X_test.copy()\n",
    "    \n",
    "    X_train2 = mn.fit_transform(X_train2)\n",
    "    X_test2 = mn.transform(X_test2)\n",
    "    \n",
    "    return X_train2,X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97242101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_transforemer_scaler(X_train,X_test):\n",
    "    pts = PowerTransformer()\n",
    "    X_train6 = X_train.copy()\n",
    "    X_test6  = X_test.copy()\n",
    "    \n",
    "    X_train6 = pts.fit_transform(X_train6)\n",
    "    X_test6 = pts.transform(X_test6)\n",
    "    \n",
    "    return X_train6,X_test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bf621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(X_train,X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train1 = X_train.copy()\n",
    "    X_test1  = X_test.copy()\n",
    "    \n",
    "    X_train1 = sc.fit_transform(X_train1)\n",
    "    X_test1 = sc.transform(X_test1)\n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7575388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(dataset,predicting_label):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y = dataset[predicting_label]\n",
    "    X = dataset.drop(predicting_label,axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f8311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinality_cols(X_train):\n",
    "    \n",
    "    low_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype == \"object\"] \n",
    "    high_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() > 10 and X_train[cname].dtype == \"object\"] \n",
    "    numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']] \n",
    "    \n",
    "    return low_cardinality_cols,high_cardinality_cols,numerical_cols\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c35bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliteddata_shape(X_train,X_test,y_train,y_test):\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12191a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train,X_test,y_train,y_test,predicted_label_type=\"object\"):\n",
    "    from sklearn.metrics import mean_absolute_error,confusion_matrix\n",
    "    from sklearn.metrics import r2_score,accuracy_score\n",
    "    \n",
    "    if predicted_label_type==\"object\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(confusion_matrix(y_test,preds))\n",
    "        print()\n",
    "        print(accuracy_score(y_test,preds))\n",
    "    \n",
    "    else:\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(mean_absolute_error(y_test, preds)) \n",
    "        print(f'R square: {r2_score(y_test,preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a0615d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_categorical(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "    drop_X_valid = X_test.select_dtypes(exclude=['object'])\n",
    "\n",
    "    print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "    score_dataset(drop_X_train, drop_X_valid, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75417159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_and_bad_labels(X_train,X_test):\n",
    "    object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "    # Columns that can be safely ordinal encoded\n",
    "    good_label_cols = [col for col in object_cols if \n",
    "                       set(X_test[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "    # Problematic columns that will be dropped from the dataset\n",
    "    bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "    print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "    print('Categorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "    \n",
    "    return good_label_cols,bad_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9026b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    # Drop categorical columns that will not be encoded\n",
    "    label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "    label_X_valid = X_test.drop(bad_label_cols, axis=1)\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "    label_X_valid[good_label_cols] = ordinal_encoder.transform(X_test[good_label_cols])\n",
    "    \n",
    "    return label_X_train,label_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a70dfda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nullvalues(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    dataset1 = dataset.dropna(axis=0)\n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b3ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymean(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(a.mean())\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymedian(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(a.median())\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eff0f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymode(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    for i in a.columns:\n",
    "        dataset1[i] = dataset1[i].fillna(dataset1[i].mode()[0])\n",
    "    dataset1[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "369cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbybfill(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(method='bfill')\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3b0cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f68c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "381b3753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 14)\n",
      "(615,)\n",
      "(303, 14)\n",
      "(303,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "\n",
      "error and metrics\n",
      "1.721737309445229\n",
      "R square: 0.9952836980832745\n"
     ]
    }
   ],
   "source": [
    "#remove null values\n",
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c3c0362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "\n",
      "error and metrics\n",
      "3.1321649170850443\n",
      "R square: 0.9698214946328316\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5d8c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "\n",
      "error and metrics\n",
      "3.0944659972615236\n",
      "R square: 0.9667388042177254\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06936e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "\n",
      "error and metrics\n",
      "3.0469739084132073\n",
      "R square: 0.9657567077865404\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aaabf3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "\n",
      "error and metrics\n",
      "2.6247978092195354\n",
      "R square: 0.9795439303117812\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab12e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc563cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND1\\D1 copy 2\\MISSING VALUES\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ff47a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 31)\n",
      "(349,)\n",
      "(172, 31)\n",
      "(172,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[100   3]\n",
      " [  6  63]]\n",
      "\n",
      "0.9476744186046512\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea70970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  6  61]]\n",
      "\n",
      "0.9521276595744681\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cd8afb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  4  63]]\n",
      "\n",
      "0.9627659574468085\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db7c08b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[117   4]\n",
      " [  4  63]]\n",
      "\n",
      "0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3adb941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  5  62]]\n",
      "\n",
      "0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc79a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 3\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND1\\D1 copy 3\\MISSING VALUES\\winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbe7f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1046, 11)\n",
      "(1046,)\n",
      "(516, 11)\n",
      "(516,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   1   0   0   0]\n",
      " [  1   0  10   3   1   0]\n",
      " [  0   0 177  40   1   0]\n",
      " [  0   0  55 141  11   1]\n",
      " [  0   0   6  28  32   0]\n",
      " [  0   0   0   6   2   0]]\n",
      "\n",
      "0.6782945736434108\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d258442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  11   8   0   0]\n",
      " [  0   0 165  50   2   0]\n",
      " [  0   0  47 150  16   0]\n",
      " [  0   0   0  41  28   1]\n",
      " [  0   0   0   0   6   1]]\n",
      "\n",
      "0.6515151515151515\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c458efbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  11   8   0   0]\n",
      " [  0   0 165  49   3   0]\n",
      " [  0   0  48 148  17   0]\n",
      " [  0   0   0  42  27   1]\n",
      " [  0   0   0   1   5   1]]\n",
      "\n",
      "0.6458333333333334\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba87dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  11   8   0   0]\n",
      " [  0   0 166  49   2   0]\n",
      " [  0   0  51 143  19   0]\n",
      " [  0   0   2  39  28   1]\n",
      " [  0   0   0   0   6   1]]\n",
      "\n",
      "0.6401515151515151\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9de542aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  11   8   0   0]\n",
      " [  0   0 162  53   2   0]\n",
      " [  0   0  51 146  16   0]\n",
      " [  0   0   2  37  30   1]\n",
      " [  0   0   0   0   6   1]]\n",
      "\n",
      "0.6420454545454546\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a484d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datset 4\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 4\\MISSING VALUES\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc94141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 8)\n",
      "(489,)\n",
      "(242, 8)\n",
      "(242,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[128  27]\n",
      " [ 33  54]]\n",
      "\n",
      "0.7520661157024794\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58ef28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[137  31]\n",
      " [ 32  54]]\n",
      "\n",
      "0.7519685039370079\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8b33df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[139  29]\n",
      " [ 36  50]]\n",
      "\n",
      "0.7440944881889764\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0388bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[134  34]\n",
      " [ 31  55]]\n",
      "\n",
      "0.7440944881889764\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5ee7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[139  29]\n",
      " [ 34  52]]\n",
      "\n",
      "0.7519685039370079\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0705f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 5\n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 5\\MISSING VALUES\\Child Immunization Dataset.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9300f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 39)\n",
      "(434,)\n",
      "(214, 39)\n",
      "(214,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[112   3]\n",
      " [  6  93]]\n",
      "\n",
      "0.9579439252336449\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca7278cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[106  11]\n",
      " [  5 101]]\n",
      "\n",
      "0.9282511210762332\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19eb58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[110   7]\n",
      " [  4 102]]\n",
      "\n",
      "0.9506726457399103\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5981d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[109   8]\n",
      " [  6 100]]\n",
      "\n",
      "0.9372197309417041\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7013e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[107  10]\n",
      " [  6 100]]\n",
      "\n",
      "0.9282511210762332\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5559332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset6\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 6\\MISSING VALUES\\hmeq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "521d0cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2253, 12)\n",
      "(2253,)\n",
      "(1111, 12)\n",
      "(1111,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1011    0]\n",
      " [  48   52]]\n",
      "\n",
      "0.9567956795679567\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ae89d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset7\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 7\\MISSING VALUES\\NFL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "89638c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789, 17)\n",
      "(789,)\n",
      "(390, 17)\n",
      "(390,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Position', 'Player', 'Drafted..tm.rnd.yr.', 'School']\n",
      "\n",
      "error and metrics\n",
      "[[390]]\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9496e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['Player', 'Drafted..tm.rnd.yr.', 'School']\n",
      "\n",
      "error and metrics\n",
      "[[178 213]\n",
      " [ 98 659]]\n",
      "\n",
      "0.7290940766550522\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b6c1b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['Player', 'Drafted..tm.rnd.yr.', 'School']\n",
      "\n",
      "error and metrics\n",
      "[[214 177]\n",
      " [ 49 708]]\n",
      "\n",
      "0.8031358885017421\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78932674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['Player', 'Drafted..tm.rnd.yr.', 'School']\n",
      "\n",
      "error and metrics\n",
      "[[173 218]\n",
      " [104 653]]\n",
      "\n",
      "0.7195121951219512\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308ea02",
   "metadata": {},
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n",
    "# this wont work because the missing values will be continous without breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bfbfb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 8\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\research paper\\5 movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd72a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2516, 27)\n",
      "(2516,)\n",
      "(1240, 27)\n",
      "(1240,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color', 'content_rating']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'movie_imdb_link', 'director_name', 'actor_1_name', 'plot_keywords', 'language', 'genres', 'country', 'movie_title', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.5317016129032258\n",
      "R square: 0.5501116399028335\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b320a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'movie_imdb_link', 'director_name', 'actor_1_name', 'plot_keywords', 'content_rating', 'language', 'genres', 'country', 'movie_title', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.5906252252252252\n",
      "R square: 0.47434854659636494\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fcef6ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'movie_imdb_link', 'director_name', 'actor_1_name', 'plot_keywords', 'content_rating', 'language', 'genres', 'country', 'movie_title', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.5905957957957958\n",
      "R square: 0.48032383900785447\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f01f56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'movie_imdb_link', 'director_name', 'actor_1_name', 'plot_keywords', 'content_rating', 'language', 'genres', 'country', 'movie_title', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.5935405405405405\n",
      "R square: 0.4771603368598747\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2673a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'movie_imdb_link', 'director_name', 'actor_1_name', 'plot_keywords', 'content_rating', 'language', 'genres', 'country', 'movie_title', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.6006978978978977\n",
      "R square: 0.46962381132483977\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "379bd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 9\n",
    "\n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 3\\D1 copy 11\\Adult ICU patients project.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "21a450d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_19112\\103554374.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 30)\n",
      "(791,)\n",
      "(390, 30)\n",
      "(390,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['DATE OF BIRTH', 'MRN', 'If previous question is Yes, Specify:', 'Nationality']\n",
      "\n",
      "error and metrics\n",
      "[[ 64  30]\n",
      " [ 23 273]]\n",
      "\n",
      "0.8641025641025641\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "872957f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['DATE OF BIRTH', 'MRN', 'If previous question is Yes, Specify:', 'Nationality']\n",
      "\n",
      "error and metrics\n",
      "[[100  27]\n",
      " [ 21 282]]\n",
      "\n",
      "0.8883720930232558\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da559fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['DATE OF BIRTH', 'MRN', 'If previous question is Yes, Specify:', 'Nationality']\n",
      "\n",
      "error and metrics\n",
      "[[ 60  25]\n",
      " [ 21 324]]\n",
      "\n",
      "0.8930232558139535\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c88d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['DATE OF BIRTH', 'MRN', 'If previous question is Yes, Specify:', 'Nationality']\n",
      "\n",
      "error and metrics\n",
      "[[ 56  29]\n",
      " [ 20 325]]\n",
      "\n",
      "0.8860465116279069\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44268b04",
   "metadata": {},
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n",
    "#this wont work because the missing values will be continous without breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "de9d8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 10\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 3\\D1 copy 12\\MISSING VALUES\\2016 County Election Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "96548f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 8)\n",
      "(1993,)\n",
      "(982, 8)\n",
      "(982,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.714967107942973\n",
      "R square: 0.7128089942161608\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d02c0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.54225295887663\n",
      "R square: 0.7344128545707527\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed6e31f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.616325959458196\n",
      "R square: 0.7332081839023319\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4796cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.535671815446339\n",
      "R square: 0.7340667758837349\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d2deb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.562182748244734\n",
      "R square: 0.7363659123662829\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5c6016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 10\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 13\\MISSING VALUES\\churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "638e6ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3308, 17)\n",
      "(3308,)\n",
      "(1630, 17)\n",
      "(1630,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 39 253  47   6   4   0   0   0   0   0]\n",
      " [ 63 426  97  16   5   0   0   0   0   0]\n",
      " [ 32 248  49   4   3   0   0   0   0   0]\n",
      " [ 20 151  34   4   2   0   0   0   0   0]\n",
      " [  8  47  10   1  13   4   0   0   0   0]\n",
      " [  1   7   2   0  12   2   0   0   0   0]\n",
      " [  1   7   1   0   2   2   0   0   0   0]\n",
      " [  1   2   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.32699386503067485\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5a91d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 32 278  28   3   4   0   0   0   0   0]\n",
      " [ 59 433  66   7   8   0   0   0   0   0]\n",
      " [ 40 285  52   4   4   0   0   0   0   0]\n",
      " [ 20 172  20   1   0   1   0   0   0   0]\n",
      " [  8  49  11   0  16   3   0   0   0   0]\n",
      " [  2  13   2   1  11   1   0   0   0   0]\n",
      " [  1   4   1   0   4   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.3242424242424242\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e161289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 32 275  30   4   4   0   0   0   0   0]\n",
      " [ 48 440  64  12   9   0   0   0   0   0]\n",
      " [ 39 293  47   3   3   0   0   0   0   0]\n",
      " [ 21 165  22   4   1   1   0   0   0   0]\n",
      " [  8  54   7   0  15   3   0   0   0   0]\n",
      " [  3  13   1   1  12   0   0   0   0   0]\n",
      " [  1   3   0   0   4   2   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0]]\n",
      "\n",
      "0.32606060606060605\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7dfec801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 36 283  19   3   4   0   0   0   0   0]\n",
      " [ 59 431  68   6   9   0   0   0   0   0]\n",
      " [ 34 282  59   6   4   0   0   0   0   0]\n",
      " [ 18 167  23   4   1   1   0   0   0   0]\n",
      " [  9  50   9   1  15   3   0   0   0   0]\n",
      " [  1  15   3   0  11   0   0   0   0   0]\n",
      " [  0   4   2   0   4   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.3303030303030303\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51e9685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset11\n",
    "\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 14\\MISSING VALUES\\healthcare-dataset-stroke-data.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ddb943f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_19112\\42280080.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset1['stroke'] = dataset1['stroke'].astype('int')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3241, 11)\n",
      "(3241,)\n",
      "(1597, 11)\n",
      "(1597,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1519    0]\n",
      " [  77    1]]\n",
      "\n",
      "0.9517845961177207\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "25ce0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1589    2]\n",
      " [  96    0]]\n",
      "\n",
      "0.941908713692946\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "16dd3ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1589    2]\n",
      " [  96    0]]\n",
      "\n",
      "0.941908713692946\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4aa00ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1589    2]\n",
      " [  96    0]]\n",
      "\n",
      "0.941908713692946\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4abee68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1590    1]\n",
      " [  95    1]]\n",
      "\n",
      "0.943094250148192\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd4c38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 12\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 15\\MISSING VALUES\\abalone.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "38dff685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2767, 8)\n",
      "(2767,)\n",
      "(1364, 8)\n",
      "(1364,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.567851906158358\n",
      "R square: 0.543043653360108\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "be697f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.574887599709935\n",
      "R square: 0.516831041417899\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bf3d7074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.571950688905004\n",
      "R square: 0.5190082345648546\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "477ad34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5802030456852794\n",
      "R square: 0.5162492282038068\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ebc58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5709064539521393\n",
      "R square: 0.5171748742869584\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ae47e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 13\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 16\\MISSING VALUES\\Pokemon.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "12ca488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 12)\n",
      "(369,)\n",
      "(183, 12)\n",
      "(183,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type1', 'type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name']\n",
      "\n",
      "error and metrics\n",
      "[[150   9]\n",
      " [  0  24]]\n",
      "\n",
      "0.9508196721311475\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0fc8db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['type1', 'name']\n",
      "\n",
      "error and metrics\n",
      "[[308   4]\n",
      " [  5  37]]\n",
      "\n",
      "0.9745762711864406\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da1fc683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['type1', 'name']\n",
      "\n",
      "error and metrics\n",
      "[[308   4]\n",
      " [  4  38]]\n",
      "\n",
      "0.9774011299435028\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f377507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['type1', 'name']\n",
      "\n",
      "error and metrics\n",
      "[[309   3]\n",
      " [  5  37]]\n",
      "\n",
      "0.9774011299435028\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69d645b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['type1', 'name']\n",
      "\n",
      "error and metrics\n",
      "[[309   3]\n",
      " [  6  36]]\n",
      "\n",
      "0.9745762711864406\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
