{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe16e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer,RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer,MaxAbsScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8d854dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxabs_scaler(X_train,X_test):\n",
    "    rs = MaxAbsScaler()\n",
    "    X_train4 = X_train.copy()\n",
    "    X_test4  = X_test.copy()\n",
    "    \n",
    "    X_train4 = rs.fit_transform(X_train4)\n",
    "    X_test4 = rs.transform(X_test4)\n",
    "    \n",
    "    return X_train4,X_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76bd83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scaler(X_train,X_test):\n",
    "    rs = RobustScaler()\n",
    "    X_train3 = X_train.copy()\n",
    "    X_test3  = X_test.copy()\n",
    "    \n",
    "    X_train3 = rs.fit_transform(X_train3)\n",
    "    X_test3 = rs.transform(X_test3)\n",
    "    \n",
    "    return X_train3,X_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff5c784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_transforemer_scaler(X_train,X_test):\n",
    "    qts = QuantileTransformer()\n",
    "    X_train5 = X_train.copy()\n",
    "    X_test5  = X_test.copy()\n",
    "    \n",
    "    X_train5 = qts.fit_transform(X_train5)\n",
    "    X_test5 = qts.transform(X_test5)\n",
    "    \n",
    "    return X_train5,X_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31e600c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train,X_test):\n",
    "    mn = MinMaxScaler()\n",
    "    X_train2 = X_train.copy()\n",
    "    X_test2  = X_test.copy()\n",
    "    \n",
    "    X_train2 = mn.fit_transform(X_train2)\n",
    "    X_test2 = mn.transform(X_test2)\n",
    "    \n",
    "    return X_train2,X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97242101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_transforemer_scaler(X_train,X_test):\n",
    "    pts = PowerTransformer()\n",
    "    X_train6 = X_train.copy()\n",
    "    X_test6  = X_test.copy()\n",
    "    \n",
    "    X_train6 = pts.fit_transform(X_train6)\n",
    "    X_test6 = pts.transform(X_test6)\n",
    "    \n",
    "    return X_train6,X_test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32bf621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(X_train,X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train1 = X_train.copy()\n",
    "    X_test1  = X_test.copy()\n",
    "    \n",
    "    X_train1 = sc.fit_transform(X_train1)\n",
    "    X_test1 = sc.transform(X_test1)\n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7575388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(dataset,predicting_label):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y = dataset[predicting_label]\n",
    "    X = dataset.drop(predicting_label,axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49f8311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinality_cols(X_train):\n",
    "    \n",
    "    low_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype == \"object\"] \n",
    "    high_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() > 10 and X_train[cname].dtype == \"object\"] \n",
    "    numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']] \n",
    "    \n",
    "    return low_cardinality_cols,high_cardinality_cols,numerical_cols\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c35bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliteddata_shape(X_train,X_test,y_train,y_test):\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12191a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train,X_test,y_train,y_test,predicted_label_type=\"object\"):\n",
    "    from sklearn.metrics import mean_absolute_error,confusion_matrix\n",
    "    from sklearn.metrics import r2_score,accuracy_score\n",
    "    \n",
    "    if predicted_label_type==\"object\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(confusion_matrix(y_test,preds))\n",
    "        print()\n",
    "        print(accuracy_score(y_test,preds))\n",
    "    \n",
    "    else:\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(mean_absolute_error(y_test, preds)) \n",
    "        print(f'R square: {r2_score(y_test,preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a0615d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_categorical(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "    drop_X_valid = X_test.select_dtypes(exclude=['object'])\n",
    "\n",
    "    print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "    score_dataset(drop_X_train, drop_X_valid, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75417159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_and_bad_labels(X_train,X_test):\n",
    "    object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "    # Columns that can be safely ordinal encoded\n",
    "    good_label_cols = [col for col in object_cols if \n",
    "                       set(X_test[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "    # Problematic columns that will be dropped from the dataset\n",
    "    bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "    print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "    print('Categorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "    \n",
    "    return good_label_cols,bad_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9026b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    # Drop categorical columns that will not be encoded\n",
    "    label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "    label_X_valid = X_test.drop(bad_label_cols, axis=1)\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "    label_X_valid[good_label_cols] = ordinal_encoder.transform(X_test[good_label_cols])\n",
    "    \n",
    "    return label_X_train,label_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a70dfda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nullvalues(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    dataset1 = dataset.dropna(axis=0)\n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46b3ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymean(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(a.mean())\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ff587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymedian(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(a.median())\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eff0f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymode(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    for i in a.columns:\n",
    "        dataset1[i] = dataset1[i].fillna(dataset1[i].mode()[0])\n",
    "    dataset1[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "369cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbybfill(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(method='bfill')\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3b0cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f68c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "381b3753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 14)\n",
      "(615,)\n",
      "(303, 14)\n",
      "(303,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "1.6864864057834352\n",
      "R square: 0.9955956530454186\n"
     ]
    }
   ],
   "source": [
    "#remove null values\n",
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c3c0362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "3.1792161874334406\n",
      "R square: 0.9648285666699064\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5d8c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "3.065188041989958\n",
      "R square: 0.968481713122613\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06936e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "3.020348052639586\n",
      "R square: 0.9693834402502652\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6aaabf3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "2.6486208732694365\n",
      "R square: 0.9780981181128975\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab12e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc563cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND1\\D1 copy 2\\MISSING VALUES\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ff47a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 31)\n",
      "(349,)\n",
      "(172, 31)\n",
      "(172,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[102   1]\n",
      " [  9  60]]\n",
      "\n",
      "0.9418604651162791\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea70970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[119   2]\n",
      " [  4  63]]\n",
      "\n",
      "0.9680851063829787\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7cd8afb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  6  61]]\n",
      "\n",
      "0.9521276595744681\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db7c08b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  4  63]]\n",
      "\n",
      "0.9627659574468085\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3adb941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[119   2]\n",
      " [  5  62]]\n",
      "\n",
      "0.9627659574468085\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc79a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 3\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND1\\D1 copy 3\\MISSING VALUES\\winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbe7f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1046, 11)\n",
      "(1046,)\n",
      "(516, 11)\n",
      "(516,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   1   0   0   0]\n",
      " [  1   0   8   5   1   0]\n",
      " [  0   0 173  44   1   0]\n",
      " [  0   0  61 133  13   1]\n",
      " [  0   0   4  27  35   0]\n",
      " [  0   0   0   5   3   0]]\n",
      "\n",
      "0.6608527131782945\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d258442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   1   1   0   0]\n",
      " [  0   0   9  10   0   0]\n",
      " [  0   0 167  48   2   0]\n",
      " [  0   0  48 148  17   0]\n",
      " [  0   0   2  38  29   1]\n",
      " [  0   0   0   2   4   1]]\n",
      "\n",
      "0.6534090909090909\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c458efbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  11   8   0   0]\n",
      " [  0   0 171  42   4   0]\n",
      " [  0   0  50 146  17   0]\n",
      " [  0   0   0  42  27   1]\n",
      " [  0   0   0   2   4   1]]\n",
      "\n",
      "0.6534090909090909\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ba87dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  11   8   0   0]\n",
      " [  0   0 163  50   4   0]\n",
      " [  0   0  47 149  17   0]\n",
      " [  0   0   2  39  28   1]\n",
      " [  0   0   0   0   6   1]]\n",
      "\n",
      "0.6458333333333334\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9de542aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  10   9   0   0]\n",
      " [  0   0 166  50   1   0]\n",
      " [  0   0  48 148  17   0]\n",
      " [  0   0   2  37  30   1]\n",
      " [  0   0   0   0   6   1]]\n",
      "\n",
      "0.6534090909090909\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a484d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datset 4\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 4\\MISSING VALUES\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc94141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 8)\n",
      "(489,)\n",
      "(242, 8)\n",
      "(242,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[131  24]\n",
      " [ 33  54]]\n",
      "\n",
      "0.7644628099173554\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58ef28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[139  29]\n",
      " [ 33  53]]\n",
      "\n",
      "0.7559055118110236\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8b33df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[141  27]\n",
      " [ 35  51]]\n",
      "\n",
      "0.7559055118110236\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0388bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[137  31]\n",
      " [ 32  54]]\n",
      "\n",
      "0.7519685039370079\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5ee7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[137  31]\n",
      " [ 33  53]]\n",
      "\n",
      "0.7480314960629921\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0705f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 5\n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 5\\MISSING VALUES\\Child Immunization Dataset.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9300f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 39)\n",
      "(434,)\n",
      "(214, 39)\n",
      "(214,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['DISTRICT', 'IS_P']\n",
      "\n",
      "error and metrics\n",
      "[[112   3]\n",
      " [  6  93]]\n",
      "\n",
      "0.9579439252336449\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca7278cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['DISTRICT', 'IS_P']\n",
      "\n",
      "error and metrics\n",
      "[[106  11]\n",
      " [  5 101]]\n",
      "\n",
      "0.9282511210762332\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19eb58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['DISTRICT', 'IS_P']\n",
      "\n",
      "error and metrics\n",
      "[[107  10]\n",
      " [  5 101]]\n",
      "\n",
      "0.9327354260089686\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5981d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['DISTRICT', 'IS_P']\n",
      "\n",
      "error and metrics\n",
      "[[108   9]\n",
      " [  5 101]]\n",
      "\n",
      "0.9372197309417041\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7013e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['DISTRICT', 'IS_P']\n",
      "\n",
      "error and metrics\n",
      "[[110   7]\n",
      " [  5 101]]\n",
      "\n",
      "0.9461883408071748\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5559332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset6\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 6\\MISSING VALUES\\hmeq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "521d0cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2253, 12)\n",
      "(2253,)\n",
      "(1111, 12)\n",
      "(1111,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1009    2]\n",
      " [  53   47]]\n",
      "\n",
      "0.9504950495049505\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4feafc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 12)\n",
      "(3993,)\n",
      "(1967, 12)\n",
      "(1967,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1489   46]\n",
      " [ 156  276]]\n",
      "\n",
      "0.8973055414336553\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08f6fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 12)\n",
      "(3993,)\n",
      "(1967, 12)\n",
      "(1967,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1487   48]\n",
      " [ 149  283]]\n",
      "\n",
      "0.8998474834773768\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbb4fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 12)\n",
      "(3993,)\n",
      "(1967, 12)\n",
      "(1967,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1483   52]\n",
      " [ 156  276]]\n",
      "\n",
      "0.8942552109811897\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba599c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 12)\n",
      "(3993,)\n",
      "(1967, 12)\n",
      "(1967,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1507   28]\n",
      " [ 193  239]]\n",
      "\n",
      "0.887646161667514\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ae89d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset7\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 7\\MISSING VALUES\\NFL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89638c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789, 17)\n",
      "(789,)\n",
      "(390, 17)\n",
      "(390,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Drafted..tm.rnd.yr.', 'School', 'Position', 'Player']\n",
      "\n",
      "error and metrics\n",
      "[[390]]\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b9496e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['School', 'Drafted..tm.rnd.yr.', 'Player']\n",
      "\n",
      "error and metrics\n",
      "[[171 220]\n",
      " [105 652]]\n",
      "\n",
      "0.7168989547038328\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b6c1b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['School', 'Drafted..tm.rnd.yr.', 'Player']\n",
      "\n",
      "error and metrics\n",
      "[[222 169]\n",
      " [ 56 701]]\n",
      "\n",
      "0.804006968641115\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "78932674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['School', 'Drafted..tm.rnd.yr.', 'Player']\n",
      "\n",
      "error and metrics\n",
      "[[163 228]\n",
      " [101 656]]\n",
      "\n",
      "0.7134146341463414\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308ea02",
   "metadata": {},
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n",
    "# this wont work because the missing values will be continous without breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bfbfb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 8\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\research paper\\5 movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fd72a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2516, 27)\n",
      "(2516,)\n",
      "(1240, 27)\n",
      "(1240,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color', 'content_rating']\n",
      "Categorical columns that will be dropped from the dataset: ['country', 'movie_title', 'plot_keywords', 'director_name', 'actor_3_name', 'actor_1_name', 'genres', 'language', 'movie_imdb_link', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.5275475806451612\n",
      "R square: 0.5515772117878344\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b320a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['country', 'movie_title', 'plot_keywords', 'content_rating', 'director_name', 'actor_3_name', 'actor_1_name', 'genres', 'language', 'movie_imdb_link', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.5915339339339338\n",
      "R square: 0.4702672427187383\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fcef6ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['country', 'movie_title', 'plot_keywords', 'content_rating', 'director_name', 'actor_3_name', 'actor_1_name', 'genres', 'language', 'movie_imdb_link', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.5943801801801801\n",
      "R square: 0.47242372092063634\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f01f56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['country', 'movie_title', 'plot_keywords', 'content_rating', 'director_name', 'actor_3_name', 'actor_1_name', 'genres', 'language', 'movie_imdb_link', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.597204804804805\n",
      "R square: 0.47484437115980527\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2673a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['country', 'movie_title', 'plot_keywords', 'content_rating', 'director_name', 'actor_3_name', 'actor_1_name', 'genres', 'language', 'movie_imdb_link', 'actor_2_name']\n",
      "\n",
      "error and metrics\n",
      "0.596693093093093\n",
      "R square: 0.47325685015344177\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "379bd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 9\n",
    "\n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 3\\D1 copy 11\\Adult ICU patients project.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21a450d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_20456\\103554374.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 30)\n",
      "(791,)\n",
      "(390, 30)\n",
      "(390,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['MRN', 'DATE OF BIRTH', 'If previous question is Yes, Specify:', 'Nationality']\n",
      "\n",
      "error and metrics\n",
      "[[ 59  35]\n",
      " [ 20 276]]\n",
      "\n",
      "0.8589743589743589\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "872957f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['MRN', 'DATE OF BIRTH', 'If previous question is Yes, Specify:', 'Nationality']\n",
      "\n",
      "error and metrics\n",
      "[[100  27]\n",
      " [ 22 281]]\n",
      "\n",
      "0.8860465116279069\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "da559fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['MRN', 'DATE OF BIRTH', 'If previous question is Yes, Specify:', 'Nationality']\n",
      "\n",
      "error and metrics\n",
      "[[ 55  30]\n",
      " [ 21 324]]\n",
      "\n",
      "0.8813953488372093\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c88d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['MRN', 'DATE OF BIRTH', 'If previous question is Yes, Specify:', 'Nationality']\n",
      "\n",
      "error and metrics\n",
      "[[ 59  26]\n",
      " [ 22 323]]\n",
      "\n",
      "0.8883720930232558\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44268b04",
   "metadata": {},
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n",
    "#this wont work because the missing values will be continous without breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de9d8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 10\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 3\\D1 copy 12\\MISSING VALUES\\2016 County Election Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "96548f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 8)\n",
      "(1993,)\n",
      "(982, 8)\n",
      "(982,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.794525254582485\n",
      "R square: 0.708972310672983\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d02c0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.706185957873618\n",
      "R square: 0.7290412501567933\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ed6e31f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.556314656914651\n",
      "R square: 0.7357114843099433\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c4796cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.590108324974924\n",
      "R square: 0.7322709095698114\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7d2deb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.578029889669008\n",
      "R square: 0.7372475910399404\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b5c6016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 10\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 13\\MISSING VALUES\\churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "638e6ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3308, 17)\n",
      "(3308,)\n",
      "(1630, 17)\n",
      "(1630,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 41 239  59   6   4   0   0   0   0   0]\n",
      " [ 56 427 103  15   5   1   0   0   0   0]\n",
      " [ 25 241  63   2   4   1   0   0   0   0]\n",
      " [ 21 157  26   6   1   0   0   0   0   0]\n",
      " [  4  47  11   2  18   1   0   0   0   0]\n",
      " [  3  11   0   0   9   1   0   0   0   0]\n",
      " [  1   8   0   0   3   1   0   0   0   0]\n",
      " [  1   2   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.3411042944785276\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5a91d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 36 276  25   3   5   0   0   0   0   0]\n",
      " [ 62 444  50   9   7   1   0   0   0   0]\n",
      " [ 37 298  45   3   2   0   0   0   0   0]\n",
      " [ 23 161  22   6   2   0   0   0   0   0]\n",
      " [  8  51  10   0  16   2   0   0   0   0]\n",
      " [  2  13   2   1  12   0   0   0   0   0]\n",
      " [  0   5   0   0   5   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.33151515151515154\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8e161289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 31 275  32   3   4   0   0   0   0   0]\n",
      " [ 52 436  69   9   5   2   0   0   0   0]\n",
      " [ 36 280  63   2   3   1   0   0   0   0]\n",
      " [ 22 160  26   5   0   1   0   0   0   0]\n",
      " [  6  52  11   0  13   5   0   0   0   0]\n",
      " [  1  15   1   0  12   1   0   0   0   0]\n",
      " [  0   5   1   0   4   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.3327272727272727\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7dfec801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 30 279  27   5   4   0   0   0   0   0]\n",
      " [ 57 437  60   9   8   2   0   0   0   0]\n",
      " [ 32 286  58   4   4   1   0   0   0   0]\n",
      " [ 20 168  21   2   2   1   0   0   0   0]\n",
      " [  8  52   9   1  16   1   0   0   0   0]\n",
      " [  3  11   2   2  12   0   0   0   0   0]\n",
      " [  0   4   1   0   5   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.3290909090909091\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba18364b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 37 269  31   4   4   0   0   0   0   0]\n",
      " [ 58 435  61   7  12   0   0   0   0   0]\n",
      " [ 30 302  46   4   3   0   0   0   0   0]\n",
      " [ 19 167  23   3   1   1   0   0   0   0]\n",
      " [  8  50  12   0  14   3   0   0   0   0]\n",
      " [  2  14   1   1  12   0   0   0   0   0]\n",
      " [  0   4   2   0   4   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.3242424242424242\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "51e9685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset11\n",
    "\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 14\\MISSING VALUES\\healthcare-dataset-stroke-data.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ddb943f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_20456\\42280080.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset1['stroke'] = dataset1['stroke'].astype('int')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3241, 11)\n",
      "(3241,)\n",
      "(1597, 11)\n",
      "(1597,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1518    1]\n",
      " [  77    1]]\n",
      "\n",
      "0.9511584220413275\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25ce0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1589    2]\n",
      " [  96    0]]\n",
      "\n",
      "0.941908713692946\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16dd3ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1590    1]\n",
      " [  96    0]]\n",
      "\n",
      "0.942501481920569\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4aa00ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1590    1]\n",
      " [  96    0]]\n",
      "\n",
      "0.942501481920569\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4abee68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1587    4]\n",
      " [  96    0]]\n",
      "\n",
      "0.9407231772377\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dd4c38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 12\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 15\\MISSING VALUES\\abalone.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "38dff685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2767, 8)\n",
      "(2767,)\n",
      "(1364, 8)\n",
      "(1364,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.563966275659824\n",
      "R square: 0.5436768520180655\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "be697f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5732124728063814\n",
      "R square: 0.5188815664528883\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf3d7074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5747715736040606\n",
      "R square: 0.5141776514466729\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "477ad34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5831472081218274\n",
      "R square: 0.512148679024566\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4ebc58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5739738941261785\n",
      "R square: 0.5155911364859544\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ae47e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 13\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 16\\MISSING VALUES\\Pokemon.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "12ca488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 12)\n",
      "(369,)\n",
      "(183, 12)\n",
      "(183,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type1', 'type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name']\n",
      "\n",
      "error and metrics\n",
      "[[151   8]\n",
      " [  1  23]]\n",
      "\n",
      "0.9508196721311475\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0fc8db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name', 'type1']\n",
      "\n",
      "error and metrics\n",
      "[[309   3]\n",
      " [  4  38]]\n",
      "\n",
      "0.980225988700565\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "da1fc683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name', 'type1']\n",
      "\n",
      "error and metrics\n",
      "[[308   4]\n",
      " [  4  38]]\n",
      "\n",
      "0.9774011299435028\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8f377507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name', 'type1']\n",
      "\n",
      "error and metrics\n",
      "[[309   3]\n",
      " [  5  37]]\n",
      "\n",
      "0.9774011299435028\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "69d645b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name', 'type1']\n",
      "\n",
      "error and metrics\n",
      "[[308   4]\n",
      " [  7  35]]\n",
      "\n",
      "0.9689265536723164\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
