{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe16e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer,RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer,MaxAbsScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d854dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxabs_scaler(X_train,X_test):\n",
    "    rs = MaxAbsScaler()\n",
    "    X_train4 = X_train.copy()\n",
    "    X_test4  = X_test.copy()\n",
    "    \n",
    "    X_train4 = rs.fit_transform(X_train4)\n",
    "    X_test4 = rs.transform(X_test4)\n",
    "    \n",
    "    return X_train4,X_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bd83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scaler(X_train,X_test):\n",
    "    rs = RobustScaler()\n",
    "    X_train3 = X_train.copy()\n",
    "    X_test3  = X_test.copy()\n",
    "    \n",
    "    X_train3 = rs.fit_transform(X_train3)\n",
    "    X_test3 = rs.transform(X_test3)\n",
    "    \n",
    "    return X_train3,X_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5c784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_transforemer_scaler(X_train,X_test):\n",
    "    qts = QuantileTransformer()\n",
    "    X_train5 = X_train.copy()\n",
    "    X_test5  = X_test.copy()\n",
    "    \n",
    "    X_train5 = qts.fit_transform(X_train5)\n",
    "    X_test5 = qts.transform(X_test5)\n",
    "    \n",
    "    return X_train5,X_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e600c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train,X_test):\n",
    "    mn = MinMaxScaler()\n",
    "    X_train2 = X_train.copy()\n",
    "    X_test2  = X_test.copy()\n",
    "    \n",
    "    X_train2 = mn.fit_transform(X_train2)\n",
    "    X_test2 = mn.transform(X_test2)\n",
    "    \n",
    "    return X_train2,X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97242101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_transforemer_scaler(X_train,X_test):\n",
    "    pts = PowerTransformer()\n",
    "    X_train6 = X_train.copy()\n",
    "    X_test6  = X_test.copy()\n",
    "    \n",
    "    X_train6 = pts.fit_transform(X_train6)\n",
    "    X_test6 = pts.transform(X_test6)\n",
    "    \n",
    "    return X_train6,X_test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bf621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(X_train,X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train1 = X_train.copy()\n",
    "    X_test1  = X_test.copy()\n",
    "    \n",
    "    X_train1 = sc.fit_transform(X_train1)\n",
    "    X_test1 = sc.transform(X_test1)\n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7575388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(dataset,predicting_label):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y = dataset[predicting_label]\n",
    "    X = dataset.drop(predicting_label,axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f8311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinality_cols(X_train):\n",
    "    \n",
    "    low_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype == \"object\"] \n",
    "    high_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() > 10 and X_train[cname].dtype == \"object\"] \n",
    "    numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']] \n",
    "    \n",
    "    return low_cardinality_cols,high_cardinality_cols,numerical_cols\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c35bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliteddata_shape(X_train,X_test,y_train,y_test):\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12191a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train,X_test,y_train,y_test,predicted_label_type=\"object\"):\n",
    "    from sklearn.metrics import mean_absolute_error,confusion_matrix\n",
    "    from sklearn.metrics import r2_score,accuracy_score\n",
    "    \n",
    "    if predicted_label_type==\"object\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(confusion_matrix(y_test,preds))\n",
    "        print()\n",
    "        print(accuracy_score(y_test,preds))\n",
    "    \n",
    "    else:\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(mean_absolute_error(y_test, preds)) \n",
    "        print(f'R square: {r2_score(y_test,preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a0615d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_categorical(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "    drop_X_valid = X_test.select_dtypes(exclude=['object'])\n",
    "\n",
    "    print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "    score_dataset(drop_X_train, drop_X_valid, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75417159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_and_bad_labels(X_train,X_test):\n",
    "    object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "    # Columns that can be safely ordinal encoded\n",
    "    good_label_cols = [col for col in object_cols if \n",
    "                       set(X_test[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "    # Problematic columns that will be dropped from the dataset\n",
    "    bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "    print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "    print('Categorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "    \n",
    "    return good_label_cols,bad_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9026b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    # Drop categorical columns that will not be encoded\n",
    "    label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "    label_X_valid = X_test.drop(bad_label_cols, axis=1)\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "    label_X_valid[good_label_cols] = ordinal_encoder.transform(X_test[good_label_cols])\n",
    "    \n",
    "    return label_X_train,label_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a70dfda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nullvalues(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    dataset1 = dataset.dropna(axis=0)\n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b3ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymean(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(a.mean())\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymedian(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(a.median())\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eff0f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymode(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    for i in a.columns:\n",
    "        dataset1[i] = dataset1[i].fillna(dataset1[i].mode()[0])\n",
    "    dataset1[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "369cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbybfill(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(method='bfill')\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3b0cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f68c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "381b3753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 14)\n",
      "(615,)\n",
      "(303, 14)\n",
      "(303,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "1.6765756504221847\n",
      "R square: 0.9957640424260459\n"
     ]
    }
   ],
   "source": [
    "#remove null values\n",
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c3c0362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "3.096067244789289\n",
      "R square: 0.9707456263113216\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5d8c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "2.940763045793399\n",
      "R square: 0.9720034340185706\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06936e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "3.06068903088392\n",
      "R square: 0.969115605531393\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aaabf3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Transmission', 'Model']\n",
      "\n",
      "error and metrics\n",
      "2.591781758709874\n",
      "R square: 0.9823242516640845\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab12e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc563cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND1\\D1 copy 2\\MISSING VALUES\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ff47a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 31)\n",
      "(349,)\n",
      "(172, 31)\n",
      "(172,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[102   1]\n",
      " [  9  60]]\n",
      "\n",
      "0.9418604651162791\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea70970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  6  61]]\n",
      "\n",
      "0.9521276595744681\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cd8afb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[119   2]\n",
      " [  4  63]]\n",
      "\n",
      "0.9680851063829787\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db7c08b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[119   2]\n",
      " [  5  62]]\n",
      "\n",
      "0.9627659574468085\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3adb941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  4  63]]\n",
      "\n",
      "0.9627659574468085\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc79a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 3\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND1\\D1 copy 3\\MISSING VALUES\\winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbe7f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1046, 11)\n",
      "(1046,)\n",
      "(516, 11)\n",
      "(516,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   1   0   0   0]\n",
      " [  1   0   8   5   1   0]\n",
      " [  0   0 173  44   1   0]\n",
      " [  0   0  65 130  13   0]\n",
      " [  0   0   4  28  34   0]\n",
      " [  0   0   0   6   2   0]]\n",
      "\n",
      "0.6531007751937985\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d258442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  11   8   0   0]\n",
      " [  0   0 166  47   4   0]\n",
      " [  0   0  48 146  19   0]\n",
      " [  0   0   2  40  27   1]\n",
      " [  0   0   0   0   6   1]]\n",
      "\n",
      "0.6439393939393939\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c458efbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  10   9   0   0]\n",
      " [  0   0 167  47   3   0]\n",
      " [  0   0  53 143  17   0]\n",
      " [  0   0   0  42  27   1]\n",
      " [  0   0   0   2   4   1]]\n",
      "\n",
      "0.6401515151515151\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba87dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0  10   9   0   0]\n",
      " [  0   0 163  51   3   0]\n",
      " [  0   0  43 151  19   0]\n",
      " [  0   0   3  41  25   1]\n",
      " [  0   0   0   0   6   1]]\n",
      "\n",
      "0.6439393939393939\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9de542aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11)\n",
      "(1071,)\n",
      "(528, 11)\n",
      "(528,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  0   0   1   1   0   0]\n",
      " [  0   0  10   9   0   0]\n",
      " [  0   0 165  48   4   0]\n",
      " [  0   0  51 148  14   0]\n",
      " [  0   0   2  39  28   1]\n",
      " [  0   0   0   3   3   1]]\n",
      "\n",
      "0.6477272727272727\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a484d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datset 4\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 4\\MISSING VALUES\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc94141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 8)\n",
      "(489,)\n",
      "(242, 8)\n",
      "(242,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[131  24]\n",
      " [ 33  54]]\n",
      "\n",
      "0.7644628099173554\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58ef28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[136  32]\n",
      " [ 32  54]]\n",
      "\n",
      "0.7480314960629921\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8b33df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[137  31]\n",
      " [ 35  51]]\n",
      "\n",
      "0.7401574803149606\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0388bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[139  29]\n",
      " [ 35  51]]\n",
      "\n",
      "0.7480314960629921\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5ee7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[139  29]\n",
      " [ 31  55]]\n",
      "\n",
      "0.7637795275590551\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0705f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 5\n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 5\\MISSING VALUES\\Child Immunization Dataset.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9300f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 39)\n",
      "(434,)\n",
      "(214, 39)\n",
      "(214,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[112   3]\n",
      " [  6  93]]\n",
      "\n",
      "0.9579439252336449\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca7278cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[108   9]\n",
      " [  6 100]]\n",
      "\n",
      "0.9327354260089686\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19eb58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[107  10]\n",
      " [  5 101]]\n",
      "\n",
      "0.9327354260089686\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5981d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[107  10]\n",
      " [  5 101]]\n",
      "\n",
      "0.9327354260089686\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7013e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['IS_P', 'DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[108   9]\n",
      " [  5 101]]\n",
      "\n",
      "0.9372197309417041\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5559332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset6\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 6\\MISSING VALUES\\hmeq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "521d0cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2253, 12)\n",
      "(2253,)\n",
      "(1111, 12)\n",
      "(1111,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1010    1]\n",
      " [  50   50]]\n",
      "\n",
      "0.9540954095409541\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4feafc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 12)\n",
      "(3993,)\n",
      "(1967, 12)\n",
      "(1967,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror and metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mscore_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobject\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mscore_dataset\u001b[1;34m(X_train, X_test, y_train, y_test, predicted_label_type)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_test,preds))\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 331\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1070\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1068\u001b[0m     )\n\u001b[1;32m-> 1070\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1086\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1088\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:895\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    890\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    891\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    892\u001b[0m         )\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 895\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    903\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:142\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://scikit-learn.org/stable/modules/impute.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m             )\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08f6fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 12)\n",
      "(3993,)\n",
      "(1967, 12)\n",
      "(1967,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1493   42]\n",
      " [ 147  285]]\n",
      "\n",
      "0.9039145907473309\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbb4fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 12)\n",
      "(3993,)\n",
      "(1967, 12)\n",
      "(1967,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1479   56]\n",
      " [ 148  284]]\n",
      "\n",
      "0.8962887646161668\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba599c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 12)\n",
      "(3993,)\n",
      "(1967, 12)\n",
      "(1967,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['REASON', 'JOB']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1514   21]\n",
      " [ 187  245]]\n",
      "\n",
      "0.8942552109811897\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"BAD\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ae89d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset7\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 7\\MISSING VALUES\\NFL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89638c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789, 17)\n",
      "(789,)\n",
      "(390, 17)\n",
      "(390,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Position', 'Player', 'School', 'Drafted..tm.rnd.yr.']\n",
      "\n",
      "error and metrics\n",
      "[[390]]\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9496e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['Player', 'School', 'Drafted..tm.rnd.yr.']\n",
      "\n",
      "error and metrics\n",
      "[[173 218]\n",
      " [109 648]]\n",
      "\n",
      "0.7151567944250871\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b6c1b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['Player', 'School', 'Drafted..tm.rnd.yr.']\n",
      "\n",
      "error and metrics\n",
      "[[222 169]\n",
      " [ 49 708]]\n",
      "\n",
      "0.8101045296167247\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78932674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 17)\n",
      "(2329,)\n",
      "(1148, 17)\n",
      "(1148,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['Player', 'School', 'Drafted..tm.rnd.yr.']\n",
      "\n",
      "error and metrics\n",
      "[[166 225]\n",
      " [ 96 661]]\n",
      "\n",
      "0.7203832752613241\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308ea02",
   "metadata": {},
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n",
    "# this wont work because the missing values will be continous without breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfbfb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 8\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\research paper\\5 movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd72a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2516, 27)\n",
      "(2516,)\n",
      "(1240, 27)\n",
      "(1240,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color', 'content_rating']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'country', 'actor_2_name', 'language', 'movie_imdb_link', 'genres', 'movie_title', 'plot_keywords', 'actor_1_name', 'director_name']\n",
      "\n",
      "error and metrics\n",
      "0.5310314516129032\n",
      "R square: 0.5508479427162967\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b320a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'country', 'actor_2_name', 'language', 'movie_imdb_link', 'genres', 'content_rating', 'movie_title', 'plot_keywords', 'actor_1_name', 'director_name']\n",
      "\n",
      "error and metrics\n",
      "0.5913795795795794\n",
      "R square: 0.4727395734249411\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fcef6ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'country', 'actor_2_name', 'language', 'movie_imdb_link', 'genres', 'content_rating', 'movie_title', 'plot_keywords', 'actor_1_name', 'director_name']\n",
      "\n",
      "error and metrics\n",
      "0.5917405405405405\n",
      "R square: 0.4833570323786107\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f01f56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'country', 'actor_2_name', 'language', 'movie_imdb_link', 'genres', 'content_rating', 'movie_title', 'plot_keywords', 'actor_1_name', 'director_name']\n",
      "\n",
      "error and metrics\n",
      "0.5946522522522522\n",
      "R square: 0.4716388622830292\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2673a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 27)\n",
      "(3378,)\n",
      "(1665, 27)\n",
      "(1665,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['color']\n",
      "Categorical columns that will be dropped from the dataset: ['actor_3_name', 'country', 'actor_2_name', 'language', 'movie_imdb_link', 'genres', 'content_rating', 'movie_title', 'plot_keywords', 'actor_1_name', 'director_name']\n",
      "\n",
      "error and metrics\n",
      "0.600863063063063\n",
      "R square: 0.4671140420312152\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"imdb_score\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "379bd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 9\n",
    "\n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 3\\D1 copy 11\\Adult ICU patients project.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21a450d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_2524\\103554374.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 30)\n",
      "(791,)\n",
      "(390, 30)\n",
      "(390,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['If previous question is Yes, Specify:', 'Nationality', 'DATE OF BIRTH', 'MRN']\n",
      "\n",
      "error and metrics\n",
      "[[ 61  33]\n",
      " [ 21 275]]\n",
      "\n",
      "0.8615384615384616\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "872957f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['If previous question is Yes, Specify:', 'Nationality', 'DATE OF BIRTH', 'MRN']\n",
      "\n",
      "error and metrics\n",
      "[[ 98  29]\n",
      " [ 24 279]]\n",
      "\n",
      "0.8767441860465116\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da559fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['If previous question is Yes, Specify:', 'Nationality', 'DATE OF BIRTH', 'MRN']\n",
      "\n",
      "error and metrics\n",
      "[[ 59  26]\n",
      " [ 21 324]]\n",
      "\n",
      "0.8906976744186047\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c88d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['If previous question is Yes, Specify:', 'Nationality', 'DATE OF BIRTH', 'MRN']\n",
      "\n",
      "error and metrics\n",
      "[[ 61  24]\n",
      " [ 24 321]]\n",
      "\n",
      "0.8883720930232558\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44268b04",
   "metadata": {},
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n",
    "#this wont work because the missing values will be continous without breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de9d8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 10\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 3\\D1 copy 12\\MISSING VALUES\\2016 County Election Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96548f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 8)\n",
      "(1993,)\n",
      "(982, 8)\n",
      "(982,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.813095926680244\n",
      "R square: 0.7093988196510861\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d02c0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.669159177532599\n",
      "R square: 0.7288656462001042\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed6e31f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.594368015863054\n",
      "R square: 0.7354732951165821\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4796cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.645967602808424\n",
      "R square: 0.7299288328901252\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d2deb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.583310030090269\n",
      "R square: 0.7364833177021173\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5c6016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 10\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 13\\MISSING VALUES\\churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "638e6ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3308, 17)\n",
      "(3308,)\n",
      "(1630, 17)\n",
      "(1630,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 34 247  55   9   4   0   0   0   0   0]\n",
      " [ 52 434 100  16   5   0   0   0   0   0]\n",
      " [ 31 234  63   4   3   1   0   0   0   0]\n",
      " [ 19 145  36   9   2   0   0   0   0   0]\n",
      " [  8  43  12   5  11   4   0   0   0   0]\n",
      " [  3   5   1   1  13   1   0   0   0   0]\n",
      " [  1   7   1   0   3   1   0   0   0   0]\n",
      " [  2   2   0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.33865030674846625\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a91d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 31 281  27   2   4   0   0   0   0   0]\n",
      " [ 47 448  62   6   9   1   0   0   0   0]\n",
      " [ 35 279  61   7   3   0   0   0   0   0]\n",
      " [ 20 162  25   5   2   0   0   0   0   0]\n",
      " [  5  53  10   0  16   3   0   0   0   0]\n",
      " [  2  13   2   1  12   0   0   0   0   0]\n",
      " [  0   4   1   0   4   1   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.34\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8e161289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 37 269  32   2   5   0   0   0   0   0]\n",
      " [ 58 433  66   7   9   0   0   0   0   0]\n",
      " [ 26 295  58   2   4   0   0   0   0   0]\n",
      " [ 23 166  20   3   2   0   0   0   0   0]\n",
      " [  9  51   8   0  17   2   0   0   0   0]\n",
      " [  3  12   2   1  12   0   0   0   0   0]\n",
      " [  0   3   2   0   4   0   1   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.3327272727272727\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7dfec801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 31 279  30   2   3   0   0   0   0   0]\n",
      " [ 54 433  65   9  11   1   0   0   0   0]\n",
      " [ 35 285  54   6   5   0   0   0   0   0]\n",
      " [ 20 158  29   6   0   1   0   0   0   0]\n",
      " [  7  52  13   0  12   3   0   0   0   0]\n",
      " [  2  13   6   0   8   1   0   0   0   0]\n",
      " [  1   4   1   0   4   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.32545454545454544\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba18364b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 22 281  33   4   5   0   0   0   0   0]\n",
      " [ 63 430  63   8   9   0   0   0   0   0]\n",
      " [ 45 277  51   9   3   0   0   0   0   0]\n",
      " [ 17 166  23   6   1   1   0   0   0   0]\n",
      " [  8  53   9   0  13   4   0   0   0   0]\n",
      " [  1  13   3   1  12   0   0   0   0   0]\n",
      " [  0   4   1   0   5   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.31636363636363635\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "51e9685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset11\n",
    "\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 14\\MISSING VALUES\\healthcare-dataset-stroke-data.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddb943f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_2524\\42280080.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset1['stroke'] = dataset1['stroke'].astype('int')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3241, 11)\n",
      "(3241,)\n",
      "(1597, 11)\n",
      "(1597,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[1518    1]\n",
      " [  78    0]]\n",
      "\n",
      "0.9505322479649343\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "25ce0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1590    1]\n",
      " [  96    0]]\n",
      "\n",
      "0.942501481920569\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "16dd3ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1588    3]\n",
      " [  96    0]]\n",
      "\n",
      "0.941315945465323\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4aa00ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1589    2]\n",
      " [  96    0]]\n",
      "\n",
      "0.941908713692946\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4abee68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1590    1]\n",
      " [  96    0]]\n",
      "\n",
      "0.942501481920569\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd4c38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 12\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 15\\MISSING VALUES\\abalone.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "38dff685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2767, 8)\n",
      "(2767,)\n",
      "(1364, 8)\n",
      "(1364,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.556884164222874\n",
      "R square: 0.5484641852635683\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "be697f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5736693255982597\n",
      "R square: 0.5146481023386247\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf3d7074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5725235678027558\n",
      "R square: 0.5167663120234325\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "477ad34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5799347353154463\n",
      "R square: 0.514211110947947\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ebc58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5733502538071067\n",
      "R square: 0.516507909647468\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ae47e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 13\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 16\\MISSING VALUES\\Pokemon.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "12ca488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 12)\n",
      "(369,)\n",
      "(183, 12)\n",
      "(183,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type1', 'type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name']\n",
      "\n",
      "error and metrics\n",
      "[[151   8]\n",
      " [  3  21]]\n",
      "\n",
      "0.9398907103825137\n"
     ]
    }
   ],
   "source": [
    "dataset1 = remove_nullvalues(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0fc8db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['type1', 'name']\n",
      "\n",
      "error and metrics\n",
      "[[308   4]\n",
      " [  5  37]]\n",
      "\n",
      "0.9745762711864406\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "da1fc683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['type1', 'name']\n",
      "\n",
      "error and metrics\n",
      "[[307   5]\n",
      " [  4  38]]\n",
      "\n",
      "0.9745762711864406\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymedian(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f377507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['type1', 'name']\n",
      "\n",
      "error and metrics\n",
      "[[310   2]\n",
      " [  5  37]]\n",
      "\n",
      "0.980225988700565\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymode(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69d645b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['type1', 'name']\n",
      "\n",
      "error and metrics\n",
      "[[309   3]\n",
      " [  5  37]]\n",
      "\n",
      "0.9774011299435028\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
