{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a94bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer,RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer,MaxAbsScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0685092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(dataset,predicting_label):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y = dataset[predicting_label]\n",
    "    X = dataset.drop(predicting_label,axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7782a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinality_cols(X_train):\n",
    "    \n",
    "    low_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype == \"object\"] \n",
    "    high_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() > 10 and X_train[cname].dtype == \"object\"] \n",
    "    numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']] \n",
    "    \n",
    "    return low_cardinality_cols,high_cardinality_cols,numerical_cols\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fab6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbybfill(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(method='bfill')\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187b219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliteddata_shape(X_train,X_test,y_train,y_test):\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec22de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train,X_test,y_train,y_test,predicted_label_type=\"object\"):\n",
    "    from sklearn.metrics import mean_absolute_error,confusion_matrix\n",
    "    from sklearn.metrics import r2_score,accuracy_score\n",
    "    \n",
    "    if predicted_label_type==\"object\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(confusion_matrix(y_test,preds))\n",
    "        print()\n",
    "        print(accuracy_score(y_test,preds))\n",
    "    \n",
    "    else:\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(mean_absolute_error(y_test, preds)) \n",
    "        print(f'R square: {r2_score(y_test,preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62aabdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_categorical(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "    drop_X_valid = X_test.select_dtypes(exclude=['object'])\n",
    "\n",
    "    print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "    score_dataset(drop_X_train, drop_X_valid, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e88a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_and_bad_labels(X_train,X_test):\n",
    "    object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "    # Columns that can be safely ordinal encoded\n",
    "    good_label_cols = [col for col in object_cols if \n",
    "                       set(X_test[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "    # Problematic columns that will be dropped from the dataset\n",
    "    bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "    print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "    print('Categorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "    \n",
    "    return good_label_cols,bad_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17216af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    # Drop categorical columns that will not be encoded\n",
    "    label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "    label_X_valid = X_test.drop(bad_label_cols, axis=1)\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "    label_X_valid[good_label_cols] = ordinal_encoder.transform(X_test[good_label_cols])\n",
    "    \n",
    "    return label_X_train,label_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "610c38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoding(X_train,X_test,y_train,y_test):\n",
    "    from sklearn.preprocessingprocessing import OneHotEncoder\n",
    "    # Drop categorical columns that will not be encoded\n",
    "    label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "    label_X_valid = X_test.drop(bad_label_cols, axis=1)\n",
    "    # Apply ordinal encoder \n",
    "    # Your code here\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    label_X_train[good_label_cols] = onehot_encoder.fit_transform(X_train[good_label_cols])\n",
    "    label_X_valid[good_label_cols] = onehot_encoder.transform(X_test[good_label_cols])\n",
    "#     print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "#     score_dataset(label_X_train, label_X_valid, y_train, y_test)\n",
    "    return label_X_train,label_X_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff151634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(X_train,X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train1 = X_train.copy()\n",
    "    X_test1  = X_test.copy()\n",
    "    \n",
    "    X_train1 = sc.fit_transform(X_train1)\n",
    "    X_test1 = sc.transform(X_test1)\n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3174d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train,X_test):\n",
    "    mn = MinMaxScaler()\n",
    "    X_train2 = X_train.copy()\n",
    "    X_test2  = X_test.copy()\n",
    "    \n",
    "    X_train2 = mn.fit_transform(X_train2)\n",
    "    X_test2 = mn.transform(X_test2)\n",
    "    \n",
    "    return X_train2,X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc2640b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scaler(X_train,X_test):\n",
    "    rs = RobustScaler()\n",
    "    X_train3 = X_train.copy()\n",
    "    X_test3  = X_test.copy()\n",
    "    \n",
    "    X_train3 = rs.fit_transform(X_train3)\n",
    "    X_test3 = rs.transform(X_test3)\n",
    "    \n",
    "    return X_train3,X_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f067ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxabs_scaler(X_train,X_test):\n",
    "    rs = MaxAbsScaler()\n",
    "    X_train4 = X_train.copy()\n",
    "    X_test4  = X_test.copy()\n",
    "    \n",
    "    X_train4 = rs.fit_transform(X_train4)\n",
    "    X_test4 = rs.transform(X_test4)\n",
    "    \n",
    "    return X_train4,X_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b8509b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_transforemer_scaler(X_train,X_test):\n",
    "    qts = QuantileTransformer()\n",
    "    X_train5 = X_train.copy()\n",
    "    X_test5  = X_test.copy()\n",
    "    \n",
    "    X_train5 = qts.fit_transform(X_train5)\n",
    "    X_test5 = qts.transform(X_test5)\n",
    "    \n",
    "    return X_train5,X_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d50e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_transforemer_scaler(X_train,X_test):\n",
    "    pts = PowerTransformer()\n",
    "    X_train6 = X_train.copy()\n",
    "    X_test6  = X_test.copy()\n",
    "    \n",
    "    X_train6 = pts.fit_transform(X_train6)\n",
    "    X_test6 = pts.transform(X_test6)\n",
    "    \n",
    "    return X_train6,X_test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a73e42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "error and metrics\n",
      "2.6659787007454736\n",
      "R square: 0.9773587238892609\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\") \n",
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "X_train_encoded,X_test_encoded = standard_scaling(X_train_encoded,X_test_encoded) \n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e5c7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "error and metrics\n",
      "2.6401368477103286\n",
      "R square: 0.9774114939310131\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\") \n",
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "X_train_encoded,X_test_encoded = min_max_scaler(X_train_encoded,X_test_encoded) \n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cf211d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "error and metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2583: UserWarning: n_quantiles (1000) is greater than the total number of samples (633). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6216863684771017\n",
      "R square: 0.9760231517191219\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\") \n",
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "X_train_encoded,X_test_encoded = quantile_transforemer_scaler(X_train_encoded,X_test_encoded) \n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b8a8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "error and metrics\n",
      "2.5949909478168256\n",
      "R square: 0.9783680749199166\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\") \n",
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "X_train_encoded,X_test_encoded = robust_scaler(X_train_encoded,X_test_encoded) \n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "226cee0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "error and metrics\n",
      "2.626476038338657\n",
      "R square: 0.9782734199479659\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\") \n",
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "X_train_encoded,X_test_encoded = power_transforemer_scaler(X_train_encoded,X_test_encoded) \n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc512ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 14)\n",
      "(633,)\n",
      "(313, 14)\n",
      "(313,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Make', 'Vehicle Class', 'Fuel Type']\n",
      "Categorical columns that will be dropped from the dataset: ['Model', 'Transmission']\n",
      "error and metrics\n",
      "2.65039190628328\n",
      "R square: 0.9773194288447995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\MY2022 Fuel Consumption Ratings.xlsx\") \n",
    "dataset1 = fillvaluesbybfill(dataset)\n",
    "\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"CO2 Emissions(g/km)\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "X_train_encoded,X_test_encoded = maxabs_scaler(X_train_encoded,X_test_encoded) \n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
