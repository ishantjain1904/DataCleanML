{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e31db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a445a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(dataset,predicting_label):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y = dataset[predicting_label]\n",
    "    X = dataset.drop(predicting_label,axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e365588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliteddata_shape(X_train,X_test,y_train,y_test):\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d81d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillvaluesbymean(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    a = dataset1.select_dtypes('number')\n",
    "    b = dataset1.select_dtypes('object')\n",
    "    \n",
    "    dataset1[a.columns] = a.fillna(a.mean())\n",
    "    dataset[b.columns]  = b.fillna(b.agg(lambda x:x.mode().values[0]))\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3356b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinality_cols(X_train):\n",
    "    \n",
    "    low_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype == \"object\"] \n",
    "    high_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() > 10 and X_train[cname].dtype == \"object\"] \n",
    "    numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']] \n",
    "    \n",
    "    return low_cardinality_cols,high_cardinality_cols,numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf13dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train,X_test,y_train,y_test,predicted_label_type=\"object\"):\n",
    "    from sklearn.metrics import mean_absolute_error,confusion_matrix\n",
    "    from sklearn.metrics import r2_score,accuracy_score\n",
    "    \n",
    "    if predicted_label_type==\"object\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(confusion_matrix(y_test,preds))\n",
    "        print()\n",
    "        print(accuracy_score(y_test,preds))\n",
    "    \n",
    "    else:\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(mean_absolute_error(y_test, preds)) \n",
    "        print(f'R square: {r2_score(y_test,preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d391ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_and_bad_labels(X_train,X_test):\n",
    "    object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "    # Columns that can be safely ordinal encoded\n",
    "    good_label_cols = [col for col in object_cols if \n",
    "                       set(X_test[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "    # Problematic columns that will be dropped from the dataset\n",
    "    bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "    print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "    print('Categorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "    \n",
    "    return good_label_cols,bad_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f5a5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    # Drop categorical columns that will not be encoded\n",
    "    label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "    label_X_valid = X_test.drop(bad_label_cols, axis=1)\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "    label_X_valid[good_label_cols] = ordinal_encoder.transform(X_test[good_label_cols])\n",
    "    \n",
    "    return label_X_train,label_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774b2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_values(dataset):\n",
    "    dataset1 = dataset.copy()\n",
    "    dataset1.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd4e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 1\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND1\\D1 copy 2\\DUPLICATE\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc44bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  5  62]]\n",
      "\n",
      "0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "dataset1 = drop_duplicate_values(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6632fd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 31)\n",
      "(381,)\n",
      "(188, 31)\n",
      "(188,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[118   3]\n",
      " [  5  62]]\n",
      "\n",
      "0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "dataset1 = dataset.copy()\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"diagnosis\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69aebf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset2\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND1\\D1 copy 3\\DUPLICATE\\winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14aa28f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 12)\n",
      "(1095,)\n",
      "(540, 12)\n",
      "(540,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  1   1   3   0   0   0]\n",
      " [  0   2  11   4   1   0]\n",
      " [  0   0 172  48   3   0]\n",
      " [  0   0  63 149  10   0]\n",
      " [  0   0   2  34  29   1]\n",
      " [  0   0   0   3   2   1]]\n",
      "\n",
      "0.6555555555555556\n"
     ]
    }
   ],
   "source": [
    "dataset1 = dataset.copy()\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04640fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 12)\n",
      "(1095,)\n",
      "(540, 12)\n",
      "(540,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[  1   1   3   0   0   0]\n",
      " [  0   2  11   4   1   0]\n",
      " [  0   0 172  48   3   0]\n",
      " [  0   0  63 149  10   0]\n",
      " [  0   0   2  34  29   1]\n",
      " [  0   0   0   3   2   1]]\n",
      "\n",
      "0.6555555555555556\n"
     ]
    }
   ],
   "source": [
    "dataset1 = drop_duplicate_values(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"quality\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b84f2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset3\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 4\\DUPLICATE\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3cc957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 9)\n",
      "(550,)\n",
      "(271, 9)\n",
      "(271,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[140  36]\n",
      " [ 29  66]]\n",
      "\n",
      "0.7601476014760148\n"
     ]
    }
   ],
   "source": [
    "dataset1 = drop_duplicate_values(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c1f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 9)\n",
      "(550,)\n",
      "(271, 9)\n",
      "(271,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[140  36]\n",
      " [ 29  66]]\n",
      "\n",
      "0.7601476014760148\n"
     ]
    }
   ],
   "source": [
    "dataset1 = dataset.copy()\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff9b6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 4\n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 5\\DUPLICATE\\Child Immunization Dataset.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dbcdc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 39)\n",
      "(451,)\n",
      "(223, 39)\n",
      "(223,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'STATE', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['DISTRICT']\n",
      "\n",
      "error and metrics\n",
      "[[107  10]\n",
      " [  6 100]]\n",
      "\n",
      "0.9282511210762332\n"
     ]
    }
   ],
   "source": [
    "dataset1 = drop_duplicate_values(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655aafc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(472, 39)\n",
      "(472,)\n",
      "(233, 39)\n",
      "(233,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['FD', 'FS']\n",
      "Categorical columns that will be dropped from the dataset: ['DISTRICT', 'STATE']\n",
      "\n",
      "error and metrics\n",
      "[[114  13]\n",
      " [  7  99]]\n",
      "\n",
      "0.9141630901287554\n"
     ]
    }
   ],
   "source": [
    "dataset1 = dataset.copy()\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"IMR\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34d3c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 5\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\send 2\\D1 copy 7\\DUPLICATE\\NFL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb7f5c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2344, 17)\n",
      "(2344,)\n",
      "(1155, 17)\n",
      "(1155,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['Position_Type', 'Drafted..tm.rnd.yr.', 'School', 'Player']\n",
      "\n",
      "error and metrics\n",
      "[[240 165]\n",
      " [ 53 697]]\n",
      "\n",
      "0.8112554112554112\n"
     ]
    }
   ],
   "source": [
    "dataset1  = drop_duplicate_values(dataset1)\n",
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3e2b983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2344, 17)\n",
      "(2344,)\n",
      "(1155, 17)\n",
      "(1155,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Player_Type', 'Position']\n",
      "Categorical columns that will be dropped from the dataset: ['Position_Type', 'Drafted..tm.rnd.yr.', 'School', 'Player']\n",
      "\n",
      "error and metrics\n",
      "[[240 165]\n",
      " [ 53 697]]\n",
      "\n",
      "0.8112554112554112\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Drafted\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b22e1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 8\n",
    "dataset = pd.read_excel(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 3\\D1 copy 11\\DUPLICATE\\Adult ICU patients project.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25bebfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 30)\n",
      "(871,)\n",
      "(430, 30)\n",
      "(430,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['If previous question is Yes, Specify:', 'Nationality', 'MRN', 'DATE OF BIRTH']\n",
      "\n",
      "error and metrics\n",
      "[[ 88  26]\n",
      " [ 21 295]]\n",
      "\n",
      "0.8906976744186047\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1['ICU Outcome'] = dataset1['ICU Outcome'].astype(int)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"ICU Outcome\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5228f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 9\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 3\\D1 copy 12\\DUPLICATE\\2016 County Election Data.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0b59677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2172, 8)\n",
      "(2172,)\n",
      "(1070, 8)\n",
      "(1070,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.052086074766354\n",
      "R square: 0.7674862216683865\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b609a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 8)\n",
      "(2023,)\n",
      "(997, 8)\n",
      "(997,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: []\n",
      "Categorical columns that will be dropped from the dataset: ['County']\n",
      "\n",
      "error and metrics\n",
      "12.445744332998997\n",
      "R square: 0.7440212442417453\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1 = drop_duplicate_values(dataset1)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Clinton-lead\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13e86a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 10\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 13\\DUPLICATE\\churn.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7185cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3626, 17)\n",
      "(3626,)\n",
      "(1787, 17)\n",
      "(1787,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 71 258  29  10   4   0   0   0   0   0]\n",
      " [ 55 495  63   6   3   1   0   0   0   0]\n",
      " [ 36 266  94   8   2   0   0   0   0   0]\n",
      " [ 21 166  16  29   1   0   0   0   0   0]\n",
      " [  5  53  10   0  30   1   0   0   0   0]\n",
      " [  3  13   3   1  11   5   0   0   0   0]\n",
      " [  0   2   1   0   7   0   0   0   0   0]\n",
      " [  2   0   1   0   3   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.4051482932288752\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b88d0c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 17)\n",
      "(3350,)\n",
      "(1650, 17)\n",
      "(1650,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['churn', 'internationalplan', 'voicemailplan']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "[[ 30 283  28   0   4   0   0   0   0   0]\n",
      " [ 60 435  63   7   8   0   0   0   0   0]\n",
      " [ 30 287  59   5   4   0   0   0   0   0]\n",
      " [ 26 162  21   4   0   1   0   0   0   0]\n",
      " [  6  56   8   0  14   3   0   0   0   0]\n",
      " [  2  14   1   1  12   0   0   0   0   0]\n",
      " [  0   5   1   0   4   0   0   0   0   0]\n",
      " [  1   1   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "0.3284848484848485\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1 = drop_duplicate_values(dataset1)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"numbercustomerservicecalls\")\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4498c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 11\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 14\\DUPLICATE\\healthcare-dataset-stroke-data.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16be30ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3800, 11)\n",
      "(3800,)\n",
      "(1872, 11)\n",
      "(1872,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1735    1]\n",
      " [  89   47]]\n",
      "\n",
      "0.9519230769230769\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06767eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 11)\n",
      "(3423,)\n",
      "(1687, 11)\n",
      "(1687,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Categorical columns that will be dropped from the dataset: ['gender']\n",
      "\n",
      "error and metrics\n",
      "[[1589    2]\n",
      " [  96    0]]\n",
      "\n",
      "0.941908713692946\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1 = drop_duplicate_values(dataset1)\n",
    "dataset1['stroke'] = dataset1['stroke'].astype('int')\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"stroke\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8969aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset12\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 15\\DUPLICATE\\abalone.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a3e69e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378, 8)\n",
      "(3378,)\n",
      "(1664, 8)\n",
      "(1664,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.3771754807692307\n",
      "R square: 0.6840222011460335\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ca10828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 8)\n",
      "(2798,)\n",
      "(1379, 8)\n",
      "(1379,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['Sex']\n",
      "Categorical columns that will be dropped from the dataset: []\n",
      "\n",
      "error and metrics\n",
      "1.5624510514865844\n",
      "R square: 0.5201811346272673\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1 = drop_duplicate_values(dataset1)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"Rings\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc97be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 13\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ishan\\Downloads\\ADA\\DATASETS\\SEND 4\\D1 copy 16\\DUPLICATE\\Pokemon.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35a44878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 12)\n",
      "(718,)\n",
      "(354, 12)\n",
      "(354,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name', 'type1']\n",
      "\n",
      "error and metrics\n",
      "[[308   4]\n",
      " [  6  36]]\n",
      "\n",
      "0.9717514124293786\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "dataset1 = drop_duplicate_values(dataset1)\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f34b9ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1088, 12)\n",
      "(1088,)\n",
      "(537, 12)\n",
      "(537,)\n",
      "\n",
      "Categorical columns that will be ordinal encoded: ['type2']\n",
      "Categorical columns that will be dropped from the dataset: ['name', 'type1']\n",
      "\n",
      "error and metrics\n",
      "[[476   3]\n",
      " [  5  53]]\n",
      "\n",
      "0.9851024208566108\n"
     ]
    }
   ],
   "source": [
    "dataset1 = fillvaluesbymean(dataset)\n",
    "\n",
    "X_train,X_test,y_train,y_test = split_train_test_data(dataset1,\"legendary\")\n",
    "\n",
    "spliteddata_shape(X_train,X_test,y_train,y_test)\n",
    "print()\n",
    "low_cardinality_cols,high_cardinality_cols,numerical_cols = cardinality_cols(X_train)\n",
    "good_label_cols,bad_label_cols = good_and_bad_labels(X_train,X_test)\n",
    "X_train_encoded,X_test_encoded = ordinal_encoding(X_train,X_test,good_label_cols,bad_label_cols)\n",
    "print()\n",
    "print(\"error and metrics\")\n",
    "score_dataset(X_train_encoded,X_test_encoded,y_train,y_test,\"object\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
